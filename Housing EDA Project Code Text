#Before we begin manipulating the data we must first inspect the data:
  select *
  from layoffs

#after inspection we create a list of tasks to complete the data cleaning process:

  #tasks
	  #step 1 - removing duplicate data
	  #step 2 - standardize data
	  #step 3 - look at null/blank values
    #step 4 - remove columns/rows that aren't necessary

#Before manipulating the data it is good practice to create a copy of the dataset in MYSQL so that the original data can be brough back in case of an irreversible mistake:
  create table layoffs_staging
	like layoffs;

	insert into layoffs_staging
	select *
	from layoffs;
		
	select *
	from layoffs_staging;



--------------------------------------------------------------------------------  Step 1 - removing duplicate data:  ------------------------------------------------------------------------------------------------------------
#We used used row_number() and a CTE to determine duplicate data and then created a new table called staging_2 to add the row_number in the table to manipulate the data to remove duplicates.

#Using row_number(_) to search for duplicate data:
  select *,
  row_number()
  over(partition by company, industry, total_laid_off, percentage_laid_off, `date`) as row_num
	from layoffs_staging;

#Using a CTE and WHERE statement to determine duplicate data.  Row numbers greater than 1 were duplicate data:
  with duplicate_cte as
  (
	select *,
  row_number()
  over(partition by company, location, industry, total_laid_off, percentage_laid_off, `date`, stage, country, funds_raised_millions) as row_num
	from layoffs_staging
  )
  select *
  from duplicate_cte
  where row_num > 1
  ;

#While inspecting our data we found the company "Casper" to be duplicate data because it had a row number greater than 1:
    select *
    from layoffs_stagingw
    where company = 'Casper';

#We then removed the found duplicate data by creating a new table copying our current data including the row_number as a column so we can use to manipulate our data. We used the engine built in MYSQL to perform this step:
  CREATE TABLE `layoffs_staging2` 
  (
  `company` text,
  `location` text,
  `industry` text,
  `total_laid_off` int DEFAULT NULL,
  `percentage_laid_off` text,
  `date` text,
  `stage` text,
  `country` text,
  `funds_raised_millions` int DEFAULT NULL,
  `row_num` int
  ) 
  ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci;

#Testing to make sure the new table reads in all data:
  select *,
  row_number()
  over(partition by company, location, industry, total_laid_off, percentage_laid_off, `date`, stage, country, funds_raised_millions) as row_num
	from layoffs_staging;

#Removing the duplicate data by using our new column - any row_num that is greater than 1 is now considered duplicate data:
  delete
  from layoffs_staging2
  where row_num > 1;
 

--------------------------------------------------------------------------------  Step 2 - Standardizing Data:  -----------------------------------------------------------------------------------------------------------------
#Our data had more than just duplicates. In order to make analysis easier we must transform our data and standardize it by removing errors.

#Using trim() to inspect for spaces before and after data entries:
  select company, trim(company)
  from layoffs_staging2;

#Updating the data using trim():
  update layoffs_staging2
  set company = trim(company);

  select distinct(industry)
  from layoffs_staging2
  order by 1;

#We found an entry with an error and are correcting it from "Crypto%" to "Crypto":
  update layoffs_staging2
  set industry = 'Crypto'
  where industry like 'crypto%';

#Using trim(trailing '.') we removed any "..." found on selected data:
  select distinct country, trim(trailing '.' from (country))
  from layoffs_staging2
  order by 1;

  update layoffs_staging2
  set country = trim(trailing '.' from (country))
  where country like 'united states%';

  select distinct country
  from layoffs_staging2
  order by 1;;

#We then moved on to correcting our dates furthering data standardization. In our dataset the date datatype was a string. We wanted to change it into a date datatype:

  

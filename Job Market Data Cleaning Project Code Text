#Before we begin manipulating the data we must first inspect the data:
  select *
  from layoffs

#After inspection we created a list of tasks to complete the data cleaning process:

  #tasks
	#step 1 - removing duplicate data
	#step 2 - standardize data
	#step 3 - look at null/blank values
    	#step 4 - remove columns/rows that aren't necessary

#Before manipulating the data it is good practice to create a copy of the dataset in MYSQL so that the original data can be brough back in case of an irreversible mistake:
  create table layoffs_staging
	like layoffs;

	insert into layoffs_staging
	select *
	from layoffs;
		
	select *
	from layoffs_staging;


--------------------------------------------------------------------------------  Step 1 - removing duplicate data:  ------------------------------------------------------------------------------------------------------------
#We used used row_number() and a CTE to determine duplicate data and then created a new table called staging_2 to add the row_number in the table to manipulate the data to remove duplicates.

#Using row_number(_) to search for duplicate data:
  select *,
  row_number()
  over(partition by company, industry, total_laid_off, percentage_laid_off, `date`) as row_num
	from layoffs_staging;

#Using a CTE and WHERE statement to determine duplicate data.  Row numbers greater than 1 were duplicate data:
  with duplicate_cte as
  (
	select *,
  row_number()
  over(partition by company, location, industry, total_laid_off, percentage_laid_off, `date`, stage, country, funds_raised_millions) as row_num
	from layoffs_staging
  )
  select *
  from duplicate_cte
  where row_num > 1
  ;

#While inspecting our data we found the company "Casper" to be duplicate data because it had a row number greater than 1:
  select *
  from layoffs_staging
  where company = 'Casper';

#We then removed the found duplicate data by creating a new table copying our current data including the row_number as a column so we can use to manipulate our data. We used the engine built in MYSQL to perform this step:
  CREATE TABLE `layoffs_staging2` 
  (
  `company` text,
  `location` text,
  `industry` text,
  `total_laid_off` int DEFAULT NULL,
  `percentage_laid_off` text,
  `date` text,
  `stage` text,
  `country` text,
  `funds_raised_millions` int DEFAULT NULL,
  `row_num` int
  ) 
  ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci;

#Testing to make sure the new table reads in all data:
  select *
  from layoffs_staging2;

#Inserting our row number data into the new row_num column 
  insert into layoffs_staging2
	select *,
  	row_number()
  	over(partition by company, location, industry, total_laid_off, percentage_laid_off, `date`, stage, country, funds_raised_millions) as row_num
	from layoffs_staging;

#Removing the duplicate data by using our new column - any row_num that is greater than 1 is now considered duplicate data:
  delete
  from layoffs_staging2
  where row_num > 1;
 

--------------------------------------------------------------------------------  Step 2 - Standardizing Data:  -----------------------------------------------------------------------------------------------------------------
#Our data had more than just duplicates. In order to make analysis easier we must transform our data and standardize it by removing errors.

#Using trim() to inspect for spaces before and after data entries:
  select company, trim(company)
  from layoffs_staging2;

#Updating the data using trim():
  update layoffs_staging2
  set company = trim(company);

  select distinct(industry)
  from layoffs_staging2
  order by 1;

#We found an entry with an error and are correcting it from "Crypto%" to "Crypto":
  update layoffs_staging2
  set industry = 'Crypto'
  where industry like 'crypto%';

#Using trim(trailing '.') we removed any "..." found on selected data:
  select distinct country, trim(trailing '.' from (country))
  from layoffs_staging2
  order by 1;

  update layoffs_staging2
  set country = trim(trailing '.' from (country))
  where country like 'united states%';

  select distinct country
  from layoffs_staging2
  order by 1;;

#We then moved on to correcting our dates furthering data standardization. In our dataset the date datatype was a string. We wanted to change it into a date datatype:
  select `date`,
  str_to_date(`date`, '%m/%d/%Y')
  from layoffs_staging2;

  update layoffs_staging2
  set `date` = str_to_date(`date`, '%m/%d/%Y');

  select `date`
  from layoffs_staging2
  order by 1;

#We altered the table with this line of code *note it is important to always use your staged data and not alter the original data*
  alter table layoffs_staging2
  modify column `date` date;

  select *
  from layoffs_staging2;


--------------------------------------------------------------------------------  Step 3 - Working with null/blank Values:  -----------------------------------------------------------------------------------------------------
#Our next step was to look for null/blank values and eiter replace or remove depending on the situation.
  select *
  from layoffs_staging2
  where total_laid_off is null and percentage_laid_off is null;

#We found there were some null entries and we started to look at what we cand do with them.  The "Industry" column had some null entries and we started there.
  select distinct industry
  from layoffs_staging2
  where industry is null 
  or industry = '';

  select *
  from layoffs_staging2
  where industry is null
  or industry = '';

#We discovered "Airbnb" had null/blank values and we double checked for other errors.
  select *
  from layoffs_staging2
  where company = 'Airbnb';

#We then joined our table with itself to see all null/blank values

  select t1.company, t1.industry, t2.company, t2.industry
  from layoffs_staging2 as t1
  join layoffs_staging2 as t2
	on t1.company = t2.company
	and t1.location = t2.location
  where (t1.industry is null or t1.industry = '')
  and t2.industry is not null;

#We then updated our blank values and made them into null values
  update layoffs_staging2
  set industry = null
  where industry = '';

#We used a self join once again and then delete to remove rows with the null values.
  update layoffs_staging2 as t1
	join layoffs_staging2 as t2
	on t1.company = t2.company
  set t1.industry = t2.industry
  where t1.industry is null
  and t2.industry is not null;

  select *
  from layoffs_staging2
  where company like 'bal%';

  select *
  from layoffs_staging2
  where total_laid_off is null and percentage_laid_off is null;

  delete
  from layoffs_staging2
  where total_laid_off is null and percentage_laid_off is null;

  select *
  from layoffs_staging2;


--------------------------------------------------------------------------------  Step 4 - Removing Unnecessary Columns:  -------------------------------------------------------------------------------------------------------
#In this step we looked at which columns were unnecessary and removed them.  In our dataset the only column we needed to remove was the "row_num" column we made earlier

  alter table layoffs_staging2
  drop column row_num;

#It is important to know that dropping a column is permanent and should only be performed on staged or duplicated tables.

#At this point the data should be all set to move on to exploratory data analysis.



